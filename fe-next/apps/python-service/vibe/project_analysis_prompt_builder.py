"""Build reusable architecture/dataflow analysis prompts from a local project path."""

from __future__ import annotations

import argparse
import json
import subprocess
from pathlib import Path
from typing import Sequence

import tomllib


DEFAULT_IGNORE = "node_modules|dist|.git|.venv|__pycache__|.next|.uv_cache"
MODULE1_FILENAME = "module1_architecture_prompt"
MODULE2_FILENAME = "module2_dataflow_prompt"

ENTRY_FILE_HINTS = (
    "__main__.py",
    "main.py",
    "app.py",
    "server.py",
    "server.ts",
    "server.js",
    "index.ts",
    "index.js",
    "App.tsx",
    "commands.py",
)

CORE_NAME_HINTS = (
    "service",
    "services",
    "core",
    "agent",
    "router",
    "manager",
    "loop",
    "provider",
    "controller",
)


MODULE1_TEMPLATE = """# Role: èµ„æ·±æŠ€æœ¯æž¶æž„å¸ˆ (Senior Architect)
# Task: é¡¹ç›®æž¶æž„ä¸Žç›®å½•èŒè´£æ·±åº¦è§£æž

## è¾“å…¥ä¿¡æ¯
æˆ‘å°†æä¾›ä¸€ä¸ªå¼€æºé¡¹ç›®çš„ **æ–‡ä»¶ç›®å½•æ ‘ (File Tree)** å’Œ **å…³é”®ä¾èµ–æ–‡ä»¶**ã€‚

## ä½ çš„ç›®æ ‡
è¯·åƒç»™æ–°å…¥èŒçš„åˆçº§å·¥ç¨‹å¸ˆè®²è§£ä¸€æ ·ï¼Œç”¨é€šä¿—æ˜“æ‡‚çš„â€œäººè¯â€å¸®æˆ‘å»ºç«‹å¯¹è¿™ä¸ªé¡¹ç›®çš„å®è§‚è®¤çŸ¥ã€‚ä¸è¦å †ç Œæœ¯è¯­ï¼Œè¦è®²æ¸…æ¥šâ€œä¸ºä»€ä¹ˆè¿™ä¹ˆè®¾è®¡â€ã€‚

## è¾“å‡ºè¦æ±‚ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)

### 1. æ ¸å¿ƒæž¶æž„ç”»åƒ (The Big Picture)
* **ä¸€å¥è¯å®šä¹‰ï¼š** è¿™ä¸ªé¡¹ç›®æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªä»€ä¹ˆç³»ç»Ÿï¼Ÿ
* **æž¶æž„æ¨¡å¼ï¼š** å®ƒæ˜¯ MVCï¼ŸDDDï¼ˆé¢†åŸŸé©±åŠ¨è®¾è®¡ï¼‰ï¼Ÿè¿˜æ˜¯å¾®æœåŠ¡ï¼Ÿæˆ–è€…æ˜¯ç®€å•çš„è„šæœ¬é›†åˆï¼Ÿ
* **æŠ€æœ¯æ ˆé€‰åž‹ç†ç”±ï¼š** æŒ‘å‡º 3-5 ä¸ªæ ¸å¿ƒåº“ï¼Œè§£é‡Šä¸ºä»€ä¹ˆé€‰å®ƒä»¬è€Œä¸æ˜¯åˆ«çš„ã€‚

### 2. ç›®å½•èŒèƒ½æ˜ å°„ (The Map)
è¯·åˆ†æžç›®å½•ç»“æž„ï¼ŒæŒ‰é‡è¦æ€§åˆ—å‡ºæ ¸å¿ƒæ–‡ä»¶å¤¹ï¼Œå¹¶æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
* **ðŸ“‚ [æ–‡ä»¶å¤¹åç§°]**
    * **èŒèƒ½æ ‡ç­¾ï¼š** (ä¾‹å¦‚ï¼šðŸ§  å¤§è„‘ / ðŸ”Œ æŽ¥å£ / ðŸŽ¨ çš®è‚¤ / ðŸ—„ï¸ ä»“åº“)
    * **äººè¯è§£é‡Šï¼š** å®ƒæ˜¯åšä»€ä¹ˆçš„ï¼Ÿå¦‚æžœä¸å†™è¿™ä¸€å±‚ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
    * **æž¶æž„å±‚çº§ï¼š** (ä¾‹å¦‚ï¼šè¡¨çŽ°å±‚ / ä¸šåŠ¡é€»è¾‘å±‚ / æ•°æ®æŒä¹…å±‚)

### 3. åˆ†å±‚æž¶æž„å›¾ (Mermaid)
è¯·ç”Ÿæˆä¸€ä¸ª Mermaid `graph TD` ä»£ç å—ï¼Œå¯è§†åŒ–å±•ç¤ºå„å±‚çº§ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼ˆä¾‹å¦‚ï¼šUI -> Service -> API -> DBï¼‰ã€‚

## å¼€å§‹åˆ†æž

### æ–‡ä»¶ç›®å½•æ ‘
```text
{tree_output}
```

### å…³é”®ä¾èµ–æ–‡ä»¶
{dependency_blocks}

### README å‰ {readme_lines} è¡Œ
```markdown
{readme_head}
```
"""


MODULE2_TEMPLATE = """# Role: å…¨æ ˆç³»ç»Ÿåˆ†æžå¸ˆ (System Analyst)
# Task: æ ¸å¿ƒé“¾è·¯æ•°æ®æµè½¬è¿½è¸ª

## è¾“å…¥ä¿¡æ¯
1. æ ¸å¿ƒä»£ç ç‰‡æ®µã€‚
2. æŒ‡å®šåœºæ™¯ï¼š**{scenario}**

## ä½ çš„ç›®æ ‡
è¯·åƒè®²æ•…äº‹ä¸€æ ·ï¼Œè¿½è¸ªæ•°æ®åœ¨ç³»ç»Ÿä¸­çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸã€‚ä¸è¦åªè´´ä»£ç ï¼Œæˆ‘è¦çœ‹çš„æ˜¯â€œæ•°æ®çš„æ—…è¡Œâ€ã€‚

## è¾“å‡ºè¦æ±‚ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)

### 1. å‰§æƒ…å¼æ•°æ®æµ (The Story)
è¯·æŒ‰æ­¥éª¤æè¿°æ•°æ®æµè½¬ï¼Œæ¯ä¸€æ­¥å¿…é¡»åŒ…å«ï¼š
* **é˜¶æ®µåç§°ï¼š** (ä¾‹å¦‚ï¼š1. è¯·æ±‚æŽ¥æ”¶ -> 2. é‰´æƒ -> 3. ä¸šåŠ¡å¤„ç†)
* **æ¶‰åŠæ–‡ä»¶ï¼š** (æ ‡å‡ºæ ¸å¿ƒæ–‡ä»¶å)
* **æ•°æ®å½¢æ€å˜åŒ–ï¼š** æ•°æ®åœ¨è¿™ä¸ªçŽ¯èŠ‚å˜æˆäº†ä»€ä¹ˆæ ·ï¼Ÿ
* **æ ¸å¿ƒé€»è¾‘ï¼š** è¿™é‡Œåšäº†ä»€ä¹ˆå…³é”®å†³ç­–ï¼Ÿ

### 2. å…³é”®ä»£ç é”šç‚¹ (The Anchors)
é’ˆå¯¹ä¸Šé¢çš„æµç¨‹ï¼Œæå–å‡ºæœ€å…³é”®çš„ 3-5 è¡Œä»£ç é€»è¾‘ï¼ˆä¸ç”¨å…¨è´´ï¼Œåªè´´æ ¸å¿ƒï¼‰ï¼Œå¹¶ç”¨æ³¨é‡Šè§£é‡Šå…¶ä½œç”¨ã€‚

### 3. æ—¶åºå›¾ (Mermaid Sequence Diagram)
è¯·ç”Ÿæˆä¸€ä¸ª Mermaid `sequenceDiagram` ä»£ç å—ï¼Œå±•ç¤ºå¯¹è±¡/æ¨¡å—ä¹‹é—´çš„äº¤äº’æ—¶åºã€‚
* å‚ä¸Žè€…(Participant) åº”è¯¥æ˜¯å…·ä½“çš„æ¨¡å—æˆ–ç±»å (e.g., `Gateway`, `AgentService`, `LLMClient`)ã€‚
* æ¶ˆæ¯(Message) åº”è¯¥æ˜¯å…·ä½“çš„æ–¹æ³•è°ƒç”¨æˆ–æ•°æ®åŒ…ã€‚

## å¼€å§‹åˆ†æž

### å…¥å£æ–‡ä»¶ç‰‡æ®µ
{entry_blocks}

### æ ¸å¿ƒé€»è¾‘æ–‡ä»¶ç‰‡æ®µ
{core_blocks}
"""


def _split_ignore(ignore_pattern: str) -> set[str]:
    return {item.strip() for item in ignore_pattern.split("|") if item.strip()}


def _depth_within(path: Path, root: Path) -> int:
    rel = path.relative_to(root)
    return len(rel.parts)


def _walk_files(project_path: Path, ignore_names: set[str], max_depth: int) -> list[Path]:
    files: list[Path] = []
    for path in sorted(project_path.rglob("*")):
        if any(part in ignore_names for part in path.parts):
            continue
        if _depth_within(path, project_path) > max_depth:
            continue
        if path.is_file():
            files.append(path)
    return files


def _run_tree(project_path: Path, max_depth: int, ignore_pattern: str) -> str:
    command = [
        "tree",
        "-I",
        ignore_pattern,
        "-L",
        str(max_depth),
        str(project_path),
    ]
    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        return result.stdout.strip() or f"{project_path} (empty)"
    except (FileNotFoundError, subprocess.CalledProcessError):
        return _fallback_tree(project_path, max_depth, _split_ignore(ignore_pattern))


def _fallback_tree(project_path: Path, max_depth: int, ignore_names: set[str]) -> str:
    def should_skip(path: Path) -> bool:
        return any(part in ignore_names for part in path.parts)

    lines = [str(project_path)]

    def walk(current: Path, prefix: str, depth: int) -> None:
        if depth >= max_depth:
            return
        entries = [
            entry
            for entry in sorted(current.iterdir(), key=lambda p: (p.is_file(), p.name.lower()))
            if not should_skip(entry)
        ]
        total = len(entries)
        for index, entry in enumerate(entries, start=1):
            connector = "â””â”€â”€ " if index == total else "â”œâ”€â”€ "
            lines.append(f"{prefix}{connector}{entry.name}")
            if entry.is_dir():
                extension = "    " if index == total else "â”‚   "
                walk(entry, prefix + extension, depth + 1)

    walk(project_path, "", 0)
    return "\n".join(lines)


def _safe_read(path: Path) -> str:
    for encoding in ("utf-8", "utf-8-sig", "latin-1"):
        try:
            return path.read_text(encoding=encoding)
        except UnicodeDecodeError:
            continue
    return ""


def _read_head_lines(path: Path, line_limit: int) -> str:
    content = _safe_read(path)
    if not content:
        return "(å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è¯»å–)"
    return "\n".join(content.splitlines()[:line_limit]).strip() or "(æ–‡ä»¶ä¸ºç©º)"


def _format_json_snippet(path: Path) -> str:
    try:
        parsed = json.loads(_safe_read(path))
    except json.JSONDecodeError:
        return _read_head_lines(path, 220)

    keys = [
        "name",
        "version",
        "private",
        "type",
        "scripts",
        "dependencies",
        "devDependencies",
    ]
    filtered = {key: parsed[key] for key in keys if key in parsed}
    return json.dumps(filtered, ensure_ascii=False, indent=2)


def _format_pyproject_snippet(path: Path) -> str:
    try:
        parsed = tomllib.loads(_safe_read(path))
    except tomllib.TOMLDecodeError:
        return _read_head_lines(path, 220)

    project = parsed.get("project", {})
    selected = {
        "name": project.get("name"),
        "version": project.get("version"),
        "requires-python": project.get("requires-python"),
        "dependencies": project.get("dependencies", []),
        "optional-dependencies": project.get("optional-dependencies", {}),
    }
    cleaned = {key: value for key, value in selected.items() if value not in (None, [], {})}
    return json.dumps(cleaned, ensure_ascii=False, indent=2)


def _format_dependency_block(path: Path) -> str:
    suffix = path.name.lower()
    if suffix == "package.json":
        body = _format_json_snippet(path)
        language = "json"
    elif suffix == "pyproject.toml":
        body = _format_pyproject_snippet(path)
        language = "json"
    else:
        body = _read_head_lines(path, 220)
        language = "text"

    return f"#### `{path}`\n```{language}\n{body}\n```"


def _collect_dependency_files(project_path: Path) -> list[Path]:
    preferred = [
        project_path / "package.json",
        project_path / "pyproject.toml",
        project_path / "requirements.txt",
    ]
    found = [path for path in preferred if path.exists()]
    if found:
        return found

    fallback: list[Path] = []
    for filename in ("package.json", "pyproject.toml", "requirements.txt"):
        fallback.extend(project_path.glob(f"*/{filename}"))
    return sorted(fallback)[:3]


def _locate_readme(project_path: Path) -> Path | None:
    for filename in ("README.md", "readme.md", "README.MD"):
        candidate = project_path / filename
        if candidate.exists():
            return candidate
    return None


def build_module1_prompt(
    project_path: Path,
    max_depth: int,
    readme_lines: int,
    ignore_pattern: str,
) -> str:
    tree_output = _run_tree(project_path, max_depth=max_depth, ignore_pattern=ignore_pattern)

    dependency_files = _collect_dependency_files(project_path)
    if dependency_files:
        dependency_blocks = "\n\n".join(_format_dependency_block(path) for path in dependency_files)
    else:
        dependency_blocks = "æœªæ‰¾åˆ° package.json / pyproject.toml / requirements.txtã€‚"

    readme_path = _locate_readme(project_path)
    if readme_path:
        readme_head = _read_head_lines(readme_path, readme_lines)
    else:
        readme_head = "(æœªæ‰¾åˆ° README.md)"

    return MODULE1_TEMPLATE.format(
        tree_output=tree_output,
        dependency_blocks=dependency_blocks,
        readme_lines=readme_lines,
        readme_head=readme_head,
    )


def _resolve_paths(project_path: Path, user_paths: Sequence[str] | None) -> list[Path]:
    if not user_paths:
        return []

    resolved: list[Path] = []
    for raw in user_paths:
        path = Path(raw)
        candidate = path if path.is_absolute() else project_path / path
        if candidate.exists() and candidate.is_file():
            resolved.append(candidate)
    return resolved


def _auto_pick_entry_files(project_path: Path, ignore_names: set[str]) -> list[Path]:
    files = _walk_files(project_path, ignore_names=ignore_names, max_depth=5)
    entries = [path for path in files if path.name in ENTRY_FILE_HINTS]
    return entries[:4]


def _auto_pick_core_files(project_path: Path, ignore_names: set[str]) -> list[Path]:
    files = _walk_files(project_path, ignore_names=ignore_names, max_depth=6)

    scored: list[tuple[int, Path]] = []
    for path in files:
        lowered = str(path.relative_to(project_path)).lower()
        score = sum(2 for hint in CORE_NAME_HINTS if f"/{hint}/" in f"/{lowered}")
        score += sum(1 for hint in CORE_NAME_HINTS if hint in path.stem.lower())
        if score > 0 and path.suffix in {".py", ".ts", ".tsx", ".js"}:
            scored.append((score, path))

    scored.sort(key=lambda item: (-item[0], len(str(item[1])), str(item[1]).lower()))

    selected: list[Path] = []
    for _, path in scored:
        if path not in selected:
            selected.append(path)
        if len(selected) >= 6:
            break
    return selected


def _fence_language(path: Path) -> str:
    mapping = {
        ".py": "python",
        ".ts": "ts",
        ".tsx": "tsx",
        ".js": "js",
        ".json": "json",
        ".toml": "toml",
        ".md": "markdown",
    }
    return mapping.get(path.suffix.lower(), "text")


def _format_code_block(path: Path, project_path: Path, max_lines: int) -> str:
    lines = _safe_read(path).splitlines()
    snippet = lines[:max_lines]
    numbered = "\n".join(f"{index + 1:>4}: {line}" for index, line in enumerate(snippet))
    rel_path = path.relative_to(project_path)
    fence = _fence_language(path)
    return f"#### `{rel_path}`\n```{fence}\n{numbered}\n```"


def _ensure_nonempty(paths: list[Path], label: str) -> str:
    if paths:
        return ""
    return f"(æœªè‡ªåŠ¨è¯†åˆ«åˆ°{label}ï¼Œè¯·é€šè¿‡å‘½ä»¤å‚æ•°æ‰‹åŠ¨æŒ‡å®šã€‚)"


def build_module2_prompt(
    project_path: Path,
    scenario: str,
    entry_files: Sequence[str] | None,
    core_files: Sequence[str] | None,
    max_lines: int,
    ignore_pattern: str,
) -> str:
    ignore_names = _split_ignore(ignore_pattern)

    resolved_entry = _resolve_paths(project_path, entry_files)
    resolved_core = _resolve_paths(project_path, core_files)

    if not resolved_entry:
        resolved_entry = _auto_pick_entry_files(project_path, ignore_names=ignore_names)
    if not resolved_core:
        resolved_core = _auto_pick_core_files(project_path, ignore_names=ignore_names)

    entry_hint = _ensure_nonempty(resolved_entry, "å…¥å£æ–‡ä»¶")
    core_hint = _ensure_nonempty(resolved_core, "æ ¸å¿ƒé€»è¾‘æ–‡ä»¶")

    entry_blocks = "\n\n".join(
        _format_code_block(path, project_path=project_path, max_lines=max_lines)
        for path in resolved_entry
    )
    core_blocks = "\n\n".join(
        _format_code_block(path, project_path=project_path, max_lines=max_lines)
        for path in resolved_core
    )

    entry_blocks = "\n\n".join(filter(None, [entry_hint, entry_blocks]))
    core_blocks = "\n\n".join(filter(None, [core_hint, core_blocks]))

    return MODULE2_TEMPLATE.format(
        scenario=scenario,
        entry_blocks=entry_blocks,
        core_blocks=core_blocks,
    )


def _default_output(project_name: str, module_name: str) -> Path:
    base = Path(__file__).resolve().parent / "vibe_output"
    base.mkdir(parents=True, exist_ok=True)
    return base / f"{project_name}_{module_name}.md"


def _write_output(content: str, output: Path) -> None:
    output.parent.mkdir(parents=True, exist_ok=True)
    output.write_text(content, encoding="utf-8")


def _build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Build architecture/dataflow analysis prompts")
    subparsers = parser.add_subparsers(dest="module", required=True)

    parser_m1 = subparsers.add_parser("module1", help="Generate module1 architecture prompt")
    parser_m1.add_argument("--project", required=True, help="Target project path")
    parser_m1.add_argument("--max-depth", type=int, default=4, help="Tree max depth")
    parser_m1.add_argument("--readme-lines", type=int, default=50, help="README head lines")
    parser_m1.add_argument("--ignore", default=DEFAULT_IGNORE, help="Tree ignore pattern")
    parser_m1.add_argument("--output", help="Output markdown path")

    parser_m2 = subparsers.add_parser("module2", help="Generate module2 dataflow prompt")
    parser_m2.add_argument("--project", required=True, help="Target project path")
    parser_m2.add_argument("--scenario", required=True, help="Scenario to trace")
    parser_m2.add_argument("--entry", action="append", help="Entry file path (repeatable)")
    parser_m2.add_argument("--core", action="append", help="Core file path (repeatable)")
    parser_m2.add_argument("--max-lines", type=int, default=220, help="Max lines per snippet")
    parser_m2.add_argument("--ignore", default=DEFAULT_IGNORE, help="File scan ignore pattern")
    parser_m2.add_argument("--output", help="Output markdown path")

    return parser


def _normalize_project_path(raw: str) -> Path:
    project_path = Path(raw).expanduser().resolve()
    if not project_path.exists() or not project_path.is_dir():
        raise ValueError(f"é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {project_path}")
    return project_path


def main(argv: Sequence[str] | None = None) -> int:
    parser = _build_parser()
    args = parser.parse_args(argv)

    project_path = _normalize_project_path(args.project)
    project_name = project_path.name

    if args.module == "module1":
        content = build_module1_prompt(
            project_path=project_path,
            max_depth=args.max_depth,
            readme_lines=args.readme_lines,
            ignore_pattern=args.ignore,
        )
        output = Path(args.output).expanduser().resolve() if args.output else _default_output(project_name, MODULE1_FILENAME)
    else:
        content = build_module2_prompt(
            project_path=project_path,
            scenario=args.scenario,
            entry_files=args.entry,
            core_files=args.core,
            max_lines=args.max_lines,
            ignore_pattern=args.ignore,
        )
        output = Path(args.output).expanduser().resolve() if args.output else _default_output(project_name, MODULE2_FILENAME)

    _write_output(content, output)
    print(f"âœ… Prompt generated: {output}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
